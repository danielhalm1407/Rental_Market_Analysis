{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2469734",
   "metadata": {},
   "source": [
    "# Extracting Data From Multiple Properties on Rightmove"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7c9713",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a9b3d34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web - Scraping and API Requests\n",
    "import requests\n",
    "from httpx import AsyncClient, Response\n",
    "from parsel import Selector\n",
    "import parsel\n",
    "import jmespath\n",
    "import asyncio\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "# Data Manipulation and Analysis\n",
    "import pandas as pd\n",
    "from pprint import pprint \n",
    "import json\n",
    "from typing import List\n",
    "from typing import TypedDict\n",
    "\n",
    "# Database Connection\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# File and System Operations\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac30ce4a",
   "metadata": {},
   "source": [
    "## Other Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4bee6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) # Display all columns in any given DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f1fc36f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# This allows one to reload the custom package without having to install it again\n",
    "%load_ext autoreload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "33a3b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this allows one to reload the custom package without having to install it again\n",
    "%autoreload 1\n",
    "\n",
    "sys.path.insert(0,'../src/')\n",
    "\n",
    "# Import the custom package and sub-packages\n",
    "%aimport rental_utils\n",
    "%aimport rental_utils.functions\n",
    "%aimport rental_utils.sql_queries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219f2e5c",
   "metadata": {},
   "source": [
    "## Make Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c6b139",
   "metadata": {},
   "source": [
    "### Set up HTTP Headers so as to Slip Through the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96cb742e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. establish HTTP client with browser-like headers to avoid being blocked\n",
    "client = AsyncClient(headers={\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\",\n",
    "    \"Accept\": \"application/json\",  # Accept json apis\n",
    "    \"Referer\": \"https://www.rightmove.co.uk/\",  # Helps mimic browser use\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9085e5",
   "metadata": {},
   "source": [
    "### Define a function that takes a location string and finds out whatr its location identifier should be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fdd32a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def find_locations(query: str) -> List[str]:\n",
    "    \"\"\"use rightmove's typeahead api to find location IDs. Returns list of location IDs in most likely order\"\"\"\n",
    "    # Tokenize the query string into two-character segments separated by slashes, as required by the API\n",
    "    tokenize_query = \"\".join(c + (\"/\" if i % 2 == 0 else \"\") for i, c in enumerate(query.upper(), start=1))\n",
    "    # Construct the URL for the typeahead API using the tokenized query\n",
    "    url = f\"https://www.rightmove.co.uk/typeAhead/uknostreet/{tokenize_query.strip('/')}/\"\n",
    "    # Make an asynchronous GET request to the API\n",
    "    response = await client.get(url)\n",
    "    # Parse the JSON response from the API\n",
    "    data = json.loads(response.text)\n",
    "    # Extract and return the list of location identifiers from the response\n",
    "    return [prediction[\"locationIdentifier\"] for prediction in data[\"typeAheadLocations\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c3c0f0",
   "metadata": {},
   "source": [
    "#### Find the location identifiers for london and cornwall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ba9ffc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGION^61294\n",
      "REGION^87490\n"
     ]
    }
   ],
   "source": [
    "london_id = (await rental_utils.functions.find_locations(\"london\"))[0]\n",
    "cornwall_id = (await find_locations(\"cornwall\"))[0]\n",
    "\n",
    "\n",
    "print(cornwall_id)\n",
    "print(london_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf3019a",
   "metadata": {},
   "source": [
    "### Define a Function that Makes the Request to Rightmove's Hidden API\n",
    "\n",
    "This requires using the hidden api endpoint (the base url), and passing through the search parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843da9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_search(location_id: str, total_results = 250) -> str:\n",
    "    \"\"\"\n",
    "    Scrapes rental property listings from Rightmove for a given location identifier, handling pagination and returning all results.\n",
    "    \"\"\"\n",
    "    RESULTS_PER_PAGE = 24\n",
    "\n",
    "    def make_url(offset: int) -> str:\n",
    "        url = \"https://www.rightmove.co.uk/api/_search?\"\n",
    "        params = {\n",
    "            \"areaSizeUnit\": \"sqm\", # the units for the size of each property\n",
    "            \"channel\": \"RENT\",  # BUY or RENT - for my puyrposes, rent is the most relevant\n",
    "            \"currencyCode\": \"GBP\", # chosen currency\n",
    "            \"includeSSTC\": \"false\", # an empty search parameter\n",
    "            \"index\": offset, # the number of the search result/property displayed at the start of the page \n",
    "            \"isFetching\": \"false\", \n",
    "            \"locationIdentifier\": location_id, # the location we wish to search for (London)\n",
    "            \"numberOfPropertiesPerPage\": RESULTS_PER_PAGE,\n",
    "            \"radius\": \"0.0\", # how far away we are allowed to be from the geographgical boundaries of the region\n",
    "            \"sortType\": \"6\", # the sorting mechanism for search results\n",
    "            \"viewType\": \"LIST\", # how results appear\n",
    "        }\n",
    "        return url + urlencode(params)\n",
    "\n",
    "    # Build the URL for the first page of results\n",
    "    url = make_url(0)\n",
    "    # print(f\"Requesting URL: {url}\")\n",
    "    # Send the request to the Rightmove API for the first page\n",
    "    first_page = await client.get(url)\n",
    "    # print(f\"First page status: {first_page.status_code}\")\n",
    "    # Parse the JSON response from the first page\n",
    "    first_page_data = first_page.json()\n",
    "    results = first_page_data[\"properties\"]\n",
    "\n",
    "    # Prepare to fetch additional pages if there are more results\n",
    "    other_pages = []\n",
    "    # rightmove sets the API limit to 1000 properties, but here max_api_results is set to 20 for demonstration/testing\n",
    "    max_api_results = 1000    \n",
    "    # The 'index' parameter in the URL specifies the starting property for each page\n",
    "    for offset in range(RESULTS_PER_PAGE, total_results, RESULTS_PER_PAGE):\n",
    "        # Stop scraping more pages when the scraper reaches the API limit\n",
    "        if offset >= max_api_results: \n",
    "            break\n",
    "        print(f\"Scheduling request for offset: {offset}\")\n",
    "        # Schedule the request for the next page\n",
    "        other_pages.append(client.get(make_url(offset)))\n",
    "    # Asynchronously (using async) gather and process all additional page responses\n",
    "    for response in asyncio.as_completed(other_pages):\n",
    "        response = await response\n",
    "        # print(f\"Received response for additional page: {response.status_code}\")\n",
    "        data = json.loads(response.text)\n",
    "        results.extend(data['properties'])\n",
    "    \n",
    "    # display the number of results that we managed to parse across multiple pages\n",
    "    total_results = len(results)\n",
    "    print(f\"Found {total_results} properties\")\n",
    "    return results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c355378",
   "metadata": {},
   "source": [
    "### Scrape Multiple Pages of Results, Each with Multiple Properties\n",
    "\n",
    "I then save this out to a large json file that is then cleaned and analysed in separate notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a06324de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduling request for offset: 24\n",
      "Scheduling request for offset: 48\n",
      "Scheduling request for offset: 72\n",
      "Scheduling request for offset: 96\n",
      "Scheduling request for offset: 120\n",
      "Scheduling request for offset: 144\n",
      "Scheduling request for offset: 168\n",
      "Scheduling request for offset: 192\n",
      "Scheduling request for offset: 216\n",
      "Scheduling request for offset: 240\n",
      "Found 275 properties\n"
     ]
    }
   ],
   "source": [
    "london_results = await scrape_search(london_id)\n",
    "with open(\"../data/rightmove_properties.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(json.dumps(london_results, indent=2))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-rental",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
